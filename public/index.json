[{"categories":null,"content":"hello~ ","date":"2022-03-18","objectID":"/new/:0:0","series":null,"tags":null,"title":"New","uri":"/new/#"},{"categories":null,"content":"反向传播算法作为一位机器学习领域的博主，第一篇博客肯定要从反向传播算法开始啦~ ","date":"2022-03-18","objectID":"/backpropagation/:0:0","series":null,"tags":null,"title":"反向传播算法","uri":"/backpropagation/#反向传播算法"},{"categories":null,"content":"简介​ 来自维基百科 ​ 首先是反向传播算法的历史沿用↓ ​ 弗拉基米尔·瓦普尼克引用（Bryson, A.E.; W.F. Denham; S.E. Dreyfus. Optimal programming problems with inequality constraints. I: Necessary conditions for extremal solutions. AIAA J. 1, 11 (1963) 2544-2550）在他的书《支持向量机》中首次发表反向传播算法。在1969年Arthur E. Bryson和何毓琦将其描述为多级动态系统优化方法。直到1974年以后在神经网络的背景下应用，并由Paul Werbos[7]、David E. Rumelhart、杰弗里·辛顿和Ronald J. Williams[1][8]的著作，它才获得认可，并引发了一场人工神经网络的研究领域的“文艺复兴”。在21世纪初人们对其失去兴趣，但在2010年后又拥有了兴趣，如今可以通过GPU等大型现代运算器件用于训练更大的网络。例如在2013年，顶级语音识别器现在使用反向传播算法训练神经网络。 ​ 那么反向传播算法是啥？↓ ​ 反向传播（英语：Backpropagation，缩写为BP）是“误差反向传播”的简称，是一种与最优化方法（如梯度下降法）结合使用的，用来训练人工神经网络的常见方法。该方法对网络中所有权重计算损失函数的梯度。这个梯度会回馈给最佳化方法，用来更新权值以最小化损失函数。 $A$ ","date":"2022-03-18","objectID":"/backpropagation/:1:0","series":null,"tags":null,"title":"反向传播算法","uri":"/backpropagation/#简介"},{"categories":null,"content":"推导","date":"2022-03-18","objectID":"/backpropagation/:2:0","series":null,"tags":null,"title":"反向传播算法","uri":"/backpropagation/#推导"},{"categories":null,"content":"a. 了解矩阵乘法假设 $$ \\textbf{A} = \\begin{bmatrix} 1 \u0026 2 \\ 3 \u0026 4 \\ \\end{bmatrix} , \\textbf{B}=\\left[ \\begin{matrix} -1 \u0026 -2 \\ -3 \u0026 -4 \\ \\end{matrix} \\right] $$ 点积（通常省略 · 符号）计算如下 $$ \\textbf{AB} = \\left[ \\begin{matrix} 1 \\times(-1) + 2\\times(-3) \u0026 1\\times (-2) +2\\times(-4)\\ 3 \\times(-1) + 4\\times(-3) \u0026 3\\times(-2) +4 \\times(-4) \\end{matrix} \\right]= \\left[ \\begin{matrix} -7 \u0026 -10\\ -15\u0026 -22 \\end{matrix} \\right] $$ 逐元素乘法如下 $$ \\textbf{A}\\odot\\textbf{B} = \\left[ \\begin{matrix} 1 \\times(-1)\u0026 2\\times(-2)\\ 3 \\times(-3)\u0026 4 \\times(-4) \\end{matrix} \\right]= \\left[ \\begin{matrix} -1 \u0026 -4\\ -9\u0026 -16 \\end{matrix} \\right] $$ ","date":"2022-03-18","objectID":"/backpropagation/:2:1","series":null,"tags":null,"title":"反向传播算法","uri":"/backpropagation/#a-了解矩阵乘法"},{"categories":null,"content":"b.了解神经网络如下图所示，这是一个神经网络 可以看到，这个神经网络的隐藏层（除了第一层输入层和最后一层输出层之外都是隐藏层）与所有上一层的神经元都连接了，我们一般称这样的层为全连接层。可以看到，图中的神经网络较为复杂，接下来，我们先看看最基本的神经元是什么样的。 ","date":"2022-03-18","objectID":"/backpropagation/:2:2","series":null,"tags":null,"title":"反向传播算法","uri":"/backpropagation/#b了解神经网络"}]